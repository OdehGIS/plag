

python
# Cell 1: Import libraries and load Week 2 features
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

print("Week 3: Building on Week 2 Feature Engineering")
python
# Cell 2: Load Week 2 processed data
# Load the cleaned data from Week 2
df = pd.read_csv('ids_week2_parsed_cleaned.csv')
ip_features = pd.read_csv('ids_week2_features_scaled_by_ip.csv')

print("Loaded Week 2 processed data:")
print(f"Main dataset: {len(df)} records")
print(f"IP features: {len(ip_features)} unique IPs")
print(f"Main dataset columns: {df.columns.tolist()}")
python
# Cell 3: Prepare temporal sequence data
# Convert timestamp and sort chronologically
df['timestamp_parsed'] = pd.to_datetime(df['timestamp_parsed'])
df = df.sort_values('timestamp_parsed').reset_index(drop=True)

# Create time-based features
df['hour'] = df['timestamp_parsed'].dt.hour
df['day_of_week'] = df['timestamp_parsed'].dt.dayofweek
df['minute'] = df['timestamp_parsed'].dt.minute

print("Temporal features created")
print(f"Time range: {df['timestamp_parsed'].min()} to {df['timestamp_parsed'].max()}")
python
# Cell 4: Encode IP addresses and merge with Week 2 features
# Encode source IPs for machine learning
le = LabelEncoder()
df['src_ip_encoded'] = le.fit_transform(df['src_ip'])

# Merge Week 2 scaled features
df_enhanced = pd.merge(df, ip_features, left_on='src_ip', right_on='ip', how='left')

print(f"Enhanced dataset: {len(df_enhanced)} records")
print(f"Unique IPs: {len(le.classes_)}")
print("Available features from Week 2:")
week2_feature_cols = [col for col in df_enhanced.columns if col.endswith('_scaled')]
print(week2_feature_cols)
python
# Cell 5: Create sequence-based target variable
# We'll predict which IP will appear next based on current IP + behavior + time
df_enhanced = df_enhanced.sort_values('timestamp_parsed').reset_index(drop=True)

# Target: next IP that will appear (encoded)
df_enhanced['next_ip_encoded'] = df_enhanced['src_ip_encoded'].shift(-1)

# Remove the last row with NaN target
df_enhanced = df_enhanced.dropna(subset=['next_ip_encoded'])
df_enhanced['next_ip_encoded'] = df_enhanced['next_ip_encoded'].astype(int)

print(f"Final dataset for training: {len(df_enhanced)} records")
print(f"Target range: {df_enhanced['next_ip_encoded'].min()} to {df_enhanced['next_ip_encoded'].max()}")
python
# Cell 6: Define feature set combining temporal and behavioral features
# Basic temporal features
basic_features = ['hour', 'day_of_week', 'minute', 'src_ip_encoded']

# Week 2 behavioral features
behavioral_features = week2_feature_cols

# All features combined
all_features = basic_features + behavioral_features

# Handle any missing values in behavioral features
X = df_enhanced[all_features].fillna(0)
y = df_enhanced['next_ip_encoded']

print(f"Using {len(all_features)} features for prediction:")
print("Temporal features:", basic_features)
print("Behavioral features:", behavioral_features)
print(f"Feature matrix: {X.shape}, Target: {y.shape}")
python
# Cell 7: Split data and train model
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print(f"Training set: {len(X_train)} records")
print(f"Testing set: {len(X_test)} records")

# Train Random Forest Classifier
clf = RandomForestClassifier(
    n_estimators=100,
    random_state=42,
    max_depth=15,
    min_samples_split=5,
    class_weight='balanced'
)

clf.fit(X_train, y_train)
print("Model trained successfully!")
python
# Cell 8: Model evaluation
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("=== MODEL EVALUATION ===")
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"Correct predictions: {np.sum(y_pred == y_test)}/{len(y_test)}")

# Feature importance
feature_importance = pd.DataFrame({
    'feature': all_features,
    'importance': clf.feature_importances_
}).sort_values('importance', ascending=False)

print("\n=== TOP 10 FEATURE IMPORTANCES ===")
for _, row in feature_importance.head(10).iterrows():
    print(f"{row['feature']}: {row['importance']:.4f}")
python
# Cell 9: Prepare recent data for prediction
# Get the most recent event for prediction
recent_data = df_enhanced.tail(1).iloc[0]
recent_ip = recent_data['src_ip']
recent_timestamp = recent_data['timestamp_parsed']

print("=== PREDICTION CONTEXT ===")
print(f"Most recent event:")
print(f"  IP: {recent_ip}")
print(f"  Time: {recent_timestamp}")
print(f"  Event: {recent_data['eventid']}")

# Prepare features for this IP
sample_features = {}
for feature in all_features:
    sample_features[feature] = [recent_data[feature]]

sample_df = pd.DataFrame(sample_features)
print(f"\nUsing {len(all_features)} features for prediction")
python
# Cell 10: Make prediction
predicted_ip_encoded = clf.predict(sample_df)[0]
prediction_probabilities = clf.predict_proba(sample_df)[0]
confidence = prediction_probabilities[predicted_ip_encoded]

print("=== PREDICTION EXECUTION ===")
print(f"Predicted encoded IP: {predicted_ip_encoded}")
print(f"Prediction confidence: {confidence:.2%}")

if 0 <= predicted_ip_encoded < len(le.classes_):
    predicted_ip = le.inverse_transform([predicted_ip_encoded])[0]
    print(f"‚úÖ PREDICTION SUCCESSFUL!")
else:
    print("‚ùå Prediction out of valid range")
    predicted_ip = None
python
# Cell 11: Show top prediction candidates
print("\n=== TOP PREDICTION CANDIDATES ===")
if predicted_ip:
    # Get top 5 predictions by probability
    top_5_indices = np.argsort(prediction_probabilities)[-5:][::-1]
    
    print("Top 5 predicted IPs with probabilities:")
    for i, idx in enumerate(top_5_indices):
        if idx < len(le.classes_):
            ip = le.inverse_transform([idx])[0]
            prob = prediction_probabilities[idx]
            status = "üéØ" if i == 0 else "  "
            print(f"{status} {i+1}. {ip}: {prob:.4f} ({prob:.2%})")
python
# Cell 12: Behavioral analysis of predicted IP
print("\n=== BEHAVIORAL ANALYSIS ===")
if predicted_ip:
    # Get behavioral profile of predicted IP from Week 2 features
    ip_behavior = ip_features[ip_features['ip'] == predicted_ip]
    
    if len(ip_behavior) > 0:
        behavior = ip_behavior.iloc[0]
        print(f"Behavioral profile for {predicted_ip}:")
        
        # Interpret key behavioral indicators
        high_risk_indicators = []
        if behavior.get('login_failed_count_scaled', 0) > 0.5:
            high_risk_indicators.append("high failed login rate")
        if behavior.get('newconn_count_scaled', 0) > 0.5:
            high_risk_indicators.append("high connection volume")
        if behavior.get('total_events_scaled', 0) > 0.5:
            high_risk_indicators.append("high total activity")
            
        if high_risk_indicators:
            print(f"  ‚ö†Ô∏è  High risk: {', '.join(high_risk_indicators)}")
        else:
            print("  ‚úÖ Normal behavioral patterns")
    else:
        print(f"  No behavioral history for {predicted_ip}")
python
# Cell 13: Final output for submission
print("=" * 70)
print("WEEK 3: PREDICTING NEXT ATTACKING IP")
print("BUILT ON WEEK 2 BEHAVIORAL FEATURES")
print("=" * 70)

if predicted_ip:
    print(f"üéØ PREDICTED NEXT ATTACKER: {predicted_ip}")
    print(f"üìä MODEL ACCURACY: {accuracy * 100:.2f}%")
    print(f"‚úÖ CONFIDENCE LEVEL: {confidence:.2%}")
    print(f"üîß FEATURES USED: {len(all_features)}")
    print(f"   - Temporal: {len(basic_features)} features")
    print(f"   - Behavioral: {len(behavioral_features)} features")
    print(f"üìà TRAINING DATA: {len(df_enhanced)} events, {len(le.classes_)} unique IPs")
    print(f"‚ö° BEHAVIORAL ANALYSIS: Based on Week 2 feature engineering")
else:
    print("‚ùå PREDICTION FAILED")
    print(f"üìä MODEL ACCURACY: {accuracy * 100:.2f}%")

print("=" * 70)
python
# Cell 14: Export prediction results
results = {
    'predicted_ip': predicted_ip if predicted_ip else 'Unknown',
    'model_accuracy': accuracy,
    'prediction_confidence': confidence if predicted_ip else 0,
    'features_used': len(all_features),
    'training_records': len(df_enhanced),
    'unique_ips': len(le.classes_),
    'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
}

results_df = pd.DataFrame([results])
results_df.to_csv('week3_prediction_results.csv', index=False)

print("Prediction results exported to 'week3_prediction_results.csv'")
print("\nResults summary:")
for key, value in results.items():
    if key != 'timestamp':
        print(f"  {key}: {value}")
